{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "using Pkg\n",
        "using CSV\n",
        "using DataFrames\n",
        "using Flux\n",
        "using Flux: onehot, onehotbatch, logitcrossentropy, reset!, throttle\n",
        "using Statistics: mean\n",
        "using Random\n",
        "Pkg.add(\"Parameters\")\n",
        "using Parameters: @with_kw"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "git-repo `https://github.com/JuliaRegistries/General.git`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
            "\u001b[90m [no changes]\u001b[39m\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
            "\u001b[90m [no changes]\u001b[39m\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "@with_kw mutable struct Args\n",
        "    lr::Float64 = 1e-3     # Learning rate \n",
        "    N::Int = 3             # Number of perceptrons in hidden layer\n",
        "    test_len::Int = 100    # Number of unique words in test data \n",
        "    word_list_len::Int = 0 # Total number of unique words\n",
        "    throttle::Int = 10     # throttle timeout\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "Args"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function to parse through each row\n",
        "#s is a string, d is the dictionary\n",
        "include(\"punctuation_strip.jl\")\n",
        "function rowParser(s,d)\n",
        "    #for every word, using key \" \", add to dictionary\n",
        "    a = split(s, \" \")\n",
        "    for word in a\n",
        "        modWord = lowercase(word)\n",
        "        modWord = string_cleaner(modWord)\n",
        "        if haskey(d, modWord)\n",
        "            d[modWord] += 1\n",
        "        else\n",
        "            d[modWord] = 1\n",
        "        end\n",
        "    end\n",
        "    return nothing\n",
        "end     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"something with a long set of strings of question at XTIMEX XTIMEX XTIMEX XTIMEX on XDATEX XDATEX 9 XDATEX 99 XDATEX XDATEX 9 \", \"some times there are to long strings to to \", \"want to remove 2 to 5 word word 2 to 6 2 to 6 10 to 41 19 to 3 to 3 to 3 to 3 to 3\", \"v 345 vv 3.6 7 v 8 w w 9 1 to 5 1 6 2 3 3 to 6 ounces of enfamil\"]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "rowParser (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add a word to the dictionary if not yet encountered\n",
        "#Merge all of the dictionaries\n",
        "function getWords(array, d)\n",
        "    for row in array #put all of the words into the dictionary\n",
        "        rowParser(row, d)\n",
        "    end\n",
        "    return d\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": [
              "getWords (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "function process_data()\n",
        "    df = CSV.File(\"/Users/rachelwu/Desktop/very_fake_diet_data.csv\") |> DataFrame! \n",
        "    col1 = df[:, 1] \n",
        "    col2 = df[:, 2]\n",
        "    args = Args()\n",
        "    \n",
        "    dict = Dict{String, Integer}()\n",
        "    #fill dictionary with words from df\n",
        "    getWords(col1, dict)\n",
        "    \n",
        "    #add a string to our dictionary that will be placeholder for words found in testing never seen before\n",
        "    dict[\"<unk>\"] = 0 \n",
        "    \n",
        "    classes = unique(col2)\n",
        "    args.class_len = length(classes)\n",
        "    words = collect(skipmissing(keys(dict)))\n",
        "    args.word_list_len = length(words)\n",
        "\n",
        "    unique(filter(x -> x âˆ‰ words, join(vcat(values(dict)...))))\n",
        "\n",
        "    #dataset = [(onehotbatch(w, words, '<unk>'), onehot(l, class_len)) (here split into sentences as outside for loop) for w in words[col1]] |> shuffle\n",
        "\n",
        "    items = []\n",
        "    for s in col1\n",
        "        push!(items, split(s, \" \"))\n",
        "    end\n",
        "    println(items[1])\n",
        "    #for loops: go through each sentence (which is broken down into individual words), go through classification\n",
        "    dataset = [(onehotbatch(s, words, \"<unk>\"), onehot(c, classes)) \n",
        "                for (s, c) in zip(items, col2)] |> shuffle\n",
        "    \n",
        "    train, test = dataset[1:end-args.test_len], dataset[end-args.test_len+1:end]\n",
        "    return train, test, args\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": [
              "process_data (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "a = Args()\n",
        "t1 , t2 = process_data(a)\n",
        "t1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.4.2",
      "language": "julia",
      "name": "julia-1.4"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.4.2"
    },
    "nteract": {
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}